# -*- coding: utf-8 -*-
"""ItoAI_S21_HW5_v4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Vc35qchysp52HSl1pEuagd7fVyEqteIP
"""

# Simple for loop to check if python3 is working.
for x in range(1, 5):  # If you ever see xrange, you are in Python 2
    print(x)  # If you ever see print x (no parenthesis), you are in Python 2

# Commented out IPython magic to ensure Python compatibility.
try:
    from google.colab import drive
    drive.mount('/content/drive', force_remount=True)
    COLAB = True
    print("Note: using Google CoLab")
#     %tensorflow_version 2.x
except:
    print("Note: not using Google CoLab")
    COLAB = False

#https://www.youtube.com/watch?v=j-3vuBynnOE

#pip install opencv-pythonimport tensorflow as tf
import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc
import os
import cv2

DATADIR = "/content/drive/My Drive/Colab Notebooks/train/"
#CATEGORIES = ["O", "Other"]
#CATEGORIES = ["X", "O"]
CATEGORIES = ["1-Tomato 3","2-Tomato 4","3-Tomato Cherry Red","4-Tomato Maroon","5-Tomato Yellow", "6-Walnut"]
#CATEGORIES = ["X", "Other"]

for category in CATEGORIES:
    path = os.path.join(DATADIR, category)
    for img in os.listdir(path):
        try:
            img_arra = cv2.imread(os.path.join(path,img),cv2.IMREAD_UNCHANGED)
            img_array = cv2.cvtColor(img_arra, cv2.COLOR_BGR2RGB)
            plt.imshow(img_array, cmap="gray")
        except Exception as e:
            pass

!ls /content/drive/My\ Drive/Colab\ Notebooks

import numpy as np
import matplotlib.pyplot as plt
import os
import cv2
import random

#DATADIR = "./train/"
#CATEGORIES = ["Jibril", "Sulayman"]
#DATADIR = "./XandO/"
#CATEGORIES = ["X", "O"]
#DATADIR = "./kagglecatsanddogs_3367a/PetImages"
#DATADIR = "./kagglecatsanddogs_small/PetImages"
#CATEGORIES = ["Dog", "Cat"]


IMG_SIZE = 50

training_data = []
def create_training_data():
    for category in CATEGORIES:
        path = os.path.join(DATADIR, category)
        class_num = CATEGORIES.index(category)
        for img in os.listdir(path):
            try:
                img_arra = cv2.imread(os.path.join(path,img),cv2.IMREAD_UNCHANGED)
                img_array = cv2.cvtColor(img_arra, cv2.COLOR_BGR2RGB)
                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))
                training_data.append([new_array,class_num])
            except Exception as e:
                pass

create_training_data()
print(len(training_data))

random.shuffle(training_data)

#for sample in training_data:
#    print(sample[1])

X=[]
Y=[]
for features, label in training_data:
    X.append(features)
    Y.append(label)
    
X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE,3)
Y = np.array(Y)
X = X/255.0

#print (X)

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.model_selection import train_test_split
import pickle
from tensorflow.keras.utils import to_categorical

#X=pickle.load(open("X.pickle", "rb"))
#Y = pickle.load(open("Y.pickle","rb"))
#print(X)

# Split into train/test
x_train, x_test, y_train, y_test = train_test_split( X, Y, test_size=0.2, random_state=42)
y_train = to_categorical(y_train , 6)
y_test = to_categorical(y_test, 6)
print("X.shape=",X.shape)
print("x_train.shape=",x_train.shape)
print("y_train.shape=",y_train.shape)
print("x_test.shape=",x_test.shape)
print("y_test.shape=",y_test.shape)

callback = EarlyStopping(monitor='val_loss', patience=5)
# This callback will stop the training when there is no improvement in
# the validation loss for five consecutive epochs.

#My code 1


#https://towardsdatascience.com/10-minutes-to-building-a-cnn-binary-image-classifier-in-tensorflow-4e216b2034aa

model = Sequential()


# Note the input shape is the desired size of the image 200x200 with 3 bytes color
# This is the first convolution
model.add(Conv2D(16, (3,3), activation='relu', input_shape=(X.shape[1:])))
model.add(MaxPooling2D(2, 2))

# The second convolution
model.add(Conv2D(32, (3,3), activation='relu'))
model.add(MaxPooling2D(2,2))

# The third convolution
model.add(Conv2D(64, (3,3), activation='relu'))
model.add(MaxPooling2D(2,2))

# The fourth convolution
model.add(Conv2D(64, (3,3), activation='relu'))
model.add(MaxPooling2D(2,2))


# Flatten the results to feed into a DNN
model.add(Flatten())

# 512 neuron hidden layer
model.add(Dense(64, activation='relu'))

# Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('dandelions') and 1 for the other ('grass')
model.add(Dense(6, activation='softmax'))

model.compile(loss="categorical_crossentropy",
              optimizer="rmsprop",
              metrics=['accuracy'])
#model.fit(x_train, y_train,batch_size=32,epochs=500,callbacks=[callback],validation_data=(x_test,y_test))
model.fit(x_train, y_train,batch_size=64,epochs=20,validation_data=(x_test,y_test),verbose=2)

import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc
import os
import cv2
import numpy as np
import random
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D
from tensorflow.keras.callbacks import EarlyStopping
import pickle
import csv

# https://youtu.be/VIROTT4iXUA
# https://www.pythontutorial.net/python-basics/python-write-csv-file/

DATADI = "/content/drive/My Drive/Colab Notebooks/test"
IMG_SIZE = 50
f = []
test_data = []
def create_test_data():
    #for category in CATEGORIES:
        #path = os.path.join(DATADIR, category)
        # = CATEGORIES.index(category)
     for img in os.listdir(DATADI):
            try:
                img_arra = cv2.imread(os.path.join(DATADI,img),cv2.IMREAD_UNCHANGED)
                img_array = cv2.cvtColor(img_arra, cv2.COLOR_BGR2RGB)
                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))
                test_data.append([new_array])
                f.append(img)
            except Exception as e:
                pass

create_test_data()
print(len(test_data))

    
test_data = np.array(test_data).reshape(-1, IMG_SIZE, IMG_SIZE,3)
test_data = test_data/255.0

m =  model.predict(test_data)

t = np.argmax(m, axis=1)
#print(t[0:4])
#print(f)

combined = []
 
for i in range(len(test_data)): 
	newlist = [f[i],t[i]+1] 
	combined.append(newlist) 


h = ['filename','category']

with open('/content/drive/My Drive/Colab Notebooks/kaggle.csv', 'w', encoding='UTF8', newline='') as f:
    writer = csv.writer(f)
    writer.writerow(h)
    writer.writerows(combined)


#print(combined[0:4])